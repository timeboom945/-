## 线性回归在统计学习中的核心特点
### 1.线性
#### 属性线性
$\hat y=\bold{w^Tx}+b$没有高次项式，都是一次项
#### 系数线性
$\bold{w}$的运算是线性的，即
$$
\bold{\hat w} =\bold{(X^TX)^{-1}X^TY}
$$
是通过线性运算得到的
#### 全局线性
直接输出线性运算后的结果，没有激活函数等非线性函数在内进行运算输出
也就是说从输入到输出（从样本点到输出预测值），所有的映射都是线性的
### 2.全局性
没有对数据空间进行分段划分，将数据空间进行统一处理
### 3.数据未加工
不对原始的数据空间进行额外的加工(比如降维)
## 线性分类、激活函数和链接函数
线性分类引入激活函数
$$
p=f(\bold{w^Tx}+b),p\in\{0,1\}
$$
将线性回归的值作为输入映射成一个一维的概率
链接函数$f^{-1}$（link function）
$$
f^{-1}(p)=\bold{w^Tx}+b
$$
将一个一维的概率映射到一个线性回归的值
## 硬分类和软分析
二分类问题
1. 硬分类
$$
输出y\in \{-1,1\}(这是个集合)
$$
硬输出与概率无关，直接输出决策边界（直接告诉你属于-1类还是1类）
比如费舍线性判别分析、感知机
2. 软分类
$$
输出p(y=1)\in [0,1]
$$
软分类输出y是类别1的概率
比如生成式的：高斯判别分析
判别式的：逻辑回归